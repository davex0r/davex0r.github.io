<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Website</title>
    <script src="https://distill.pub/template.v2.js"></script>
    <link rel="stylesheet" href="styles.css">
    <script src="scripts.js"></script>
</head>


<body>
  <div class="container">

    <div class="sidebar">
      <div class="outer-div">
        <div class="circular-frame">
          <img src="manifold.png" alt="Image">
        </div>
    </div>
      <a href="index.html" class="active">Home</a>
      <a href="about.html">About</a>
      <a href="publications.html">Publications</a>
      <a href="contact.html">Contact</a>
    </div>

  <div class="content">
  <h2>Research Interests</h2>
      <p>Biology abounds with complex high-dimensional systems whose behaviour depend on an overwhelming number of microscopic processes that span a vast range of time and length scales. Yet, somehow, these systems are able to organize themselves to faithfully reproduce, reliably carry out functions, adapt to changing environments, and overcome unforeseen challenges. Biological systems across scales, from single cells to entire ecosystems, seem to be organized to be robust, yet also flexible. They can respond to changing inputs, find new steady states, persist, innovate, and adapt. Even at the level of single cells, complex behaviors are apparent. Cells “make decisions” about when to divide, or which fate to assume during differentiation, they “measure” concentrations of nutrients over time or space to “navigate” gradients. They “recognize” sites of DNA damage or mis incorporated bases for “error correction” and “repair”. Cells, carry out complex computations that govern their function, and these computations emerge from the physics of the interactions between the molecules that compose them. How is this computation happening, where is it happening, and are their signatures of it happening we can measure? How do biological systems at all scales organize themselves such that they can carry out these computations, how do these systems learn to adjust these computations to reflect their changing environments, and how does this organization give rise to robustness and flexibility? These properties seem to me to be defining for biology. Life has, after all, persisted for billions of years and at the same time created the diversity of form and function we see today. </p>

    <div class="expandable" onclick="toggleContent('expandableContent1')">Discrimination in out of equilibrium chemical networks</div>
    <div class="content-area" id="expandableContent1">
      <p>At a fundamental level, computation requires the manipulation of entropy using energy. In silicon computers this is the rewriting of bits in a realization of a Turing machine. In a chemical system, storing of information is still crucial, but computations are unlikely to be carried out with a Turing architecture. Nonetheless, the distinguishability of states, for example, the binding of a transcription factor to its “correct” binding site on the DNA (rather than some random site) is crucial for cellular information processing and thus for computation<d-cite key="Hopfield1974-mq, Ninio1975-rg"></d-cite>. This ability to distinguish states is a form of information and it can be quantified, relating thermodynamic entropy and the entropy of information theory<d-cite key="Szilard1929-js"></d-cite>. In recent work with Gaurav Venkataraman, we have explored this distinguishability, or discrimination, of states in out of equilibrium chemical networks and related it to dissipation in these networks<d-cite key="Murugan2014-hb, Murugan2012-qi, Wong2018-ys, Mirzaev2013-in"></d-cite>.  We have discovered a quantity that relates the organization of a biochemical network (i.e. its topology and rate constants) to its ability to spend energy to improve accuracy in discrimination tasks<d-cite key="Sartori2013-ov, Rao2015-ax"></d-cite> via different discriminatory mechanisms.  This quantity allowed us to discover a distinction between what we call processive and distributive complex formation, which seem well suited for energy efficient recall and energy intensive improvisation respectively. In the future, I would continue this work by looking at the relationship between steady-state concentrations and steady-state fluxes in out of equilibrium systems based on some initial results I have relating orthogonality to the matrix condition number.  Our results predict that distributive complex formation should be dissipative, rely on decreased kinetic barriers, and involve molecules with many heterogeneous, multivalent interactions. These are features of intracellular liquid like droplets that are often composed of proteins containing intrinsically disordered regions and of nucleic acids. I would like to investigate how proteins with IDRs, such as many transcription factors<d-cite key="Brodsky2020-pk"></d-cite>, might make use of processive vs distributive complex assembly for recalling or improvising gene regulatory patterns respectively. </p>
      <div class="collapse-button" onclick="toggleContent('expandableContent1')">Click to Collapse</div>
    </div>

    <div class="expandable" onclick="toggleContent('expandableContent4')">Optically addressable spin-based quantum sensors to measure sub-cellular heterogeneities</div>
      <div class="content-area" id="expandableContent4">
      <p>Possible signatures of cellular computation by out of equilibrium processes are the presence of sub-cellular heterogeneities, such as gradients of temperature, pH, chemical potential, and electric fields. One very promising new technology for measuring sub-cellular heterogeneities is Optically Detected Magnetic Resonance using NV center nano-diamonds<d-cite key="Gu2023-xo"></d-cite>, I propose to use ODMR to address the so-called “hot mitochondria paradox”, a disagreement between theory and experiment with regard to local temperature gradients at mitochondria<d-cite key="Macherel2021-jr"></d-cite>.  Although experiments have measured sustained mitochondrial temperatures of around 10°C<d-cite key="Chretien2018-yt"></d-cite> using a variety of methods, theoretical results predict stable gradients of less than 10-5.  With collaborators Sophia Belser, Helena Knowles and Mete Atature in the Caavendish Laboratory, we seek to measure the temperature around mitochondria and if we confirm large gradients, develop new theories to account for how they might arise, first looking at how large proton gradients and electrochemical differences across the mitochondrial membrane might drive temperature gradients in a Peltier-like effect<d-cite key="Keil2017-dt"></d-cite> based on Onsager's treatment of transport phenomena<d-cite key="Onsager1931-eh"></d-cite>. If we are able to measure such large differences at the sub-cellular scale, it would be a promising starting point to test the limits of NV based sensors, in hopes that they are sensitive enough to detect the nanoscale signatures of computations being carried out at the sub-cellular level.</p>
      <div class="collapse-button" onclick="toggleContent('expandableContent4')">Click to Collapse</div>
    </div>

    <div class="expandable" onclick="toggleContent('expandableContent5')">Scalable fast stochastic simulation of gene-regulatory network dynamics in Julia</div>
      <div class="content-area" id="expandableContent5">
        <p>Sub-cellular computation by chemical reaction network dynamics propagates upward to determine how cells may compute using gene regulatory network dynamics.  These dynamics are determined by myriad molecular processes such as transcription factor binding, promoter activation, histone modification, DNA condensation, alternative splicing, RNA interference, and protein mediated degradation, among many others.  Currently, I am also collaborating with Hajk-Georg Drost and colleagues at the MPI for Biology in Tübingen working on physically based models of gene expression dynamics that can capture all of these mechanisms and more.  Extending chemical master equation models of promoter dynamics pioneered by Rob Phillips and Jane Kondev<d-cite key="Bintu2005-ix, Bintu2005-xt, Sanchez2011-dm, Jones2014-og"></d-cite>, we have built a fast gene expression dynamics simulator in Julia that can run exact stochastic simulations for hundreds of coupled genes.  If cells use gene expression dynamics as a form of computation, then the temporal dynamics that are realizable from coupling genes together serve as a function space which can be used to approximate other dynamics that cells or organisms wish to generate or model.  Some examples include a bifurcation to two different cell identities or a stable oscillator<d-cite key="Otero-Muras2023-za, Perez-Carrasco2018-ug"></d-cite>.  While these cases have been studied individually in great detail, we aim to describe the space of possible functions that can be approximated<d-cite key="Verd2014-dz,Jimenez2017-rn,Verd2019-gx"></d-cite> and how these change with the inclusion of different modes of regulation. This may lead to new ways of thinking about different genetic and epigenetic control mechanisms as ways of expanding the function space of gene regulatory dynamics and making explicit predictions of what new functions can be imparted by each new mechanism.</p><p>We are particularly interested in defining causal structure in such networks. Finding casual structure in complex systems like biological networks presents many challenges.  Biological networks are known to be highly interconnected, and phenotypes result from the epistatic effects of many interacting genes.  Intriguingly, there are many examples in biology of so-called "single locus, large effect" genes, which seem to have an outsized contribution to a single phenotype.  These examples may be misleading however, as often a gene that is thought to be causal for only one phenotype in fact influences other phenotypes.  Asking "what gene is causal for this phenotype" may be similarly ill-posed as asking "which pixel makes this a picture of a dog".  Rather than individual micro variables, like pixels, we often think of causality in terms of macro variables <d-cite key="Chalupka2017-ck, Chalupka2015-lf"></d-cite>, i.e. features of collections of pixels, for example having four legs, a tail, fur, etc.  Indeed, the features, and the definition of causality itself will depend on the context, as what is required to be causal for a dog compared to a bird will be different from that which will be causal when differentiating between a dog and a wolf. Thus, features must be inferred simultaneously with causality, as different sets of features may perform better or worse depending on the inference task at hand. Causal inference of gene regulatory dynamics poses similar challenges.  For example, in a simple three gene oscillator, it does not make much sense to ask which gene causes the oscillations, as it is a feature that requires all three genes.  In addition, it not only requires their presence, but also that the rate constants of their expression and interaction dynamics place the system in an oscillatory part of phase space.  In this case it makes more sense to ask, which rates are causal of the oscillations, or which rates cause changes in the frequency of the oscillations.  If these rates can be affected by the expression of other proteins, e.g. proteins that tag the oscillating genes for degradation or interact at their promoters, then we can find causal features that influence the "oscillatory behavior" phenotype. </p>
        <div class="collapse-button" onclick="toggleContent('expandableContent5')">Click to Collapse</div>
    </div>


    <div class="expandable" onclick="toggleContent('expandableContent2')">Transfer operator models of animal behavior</div>
      <div class="content-area" id="expandableContent2">
      <p>In the context of the preceding discussion, we may think of the behavior of a cell as the computational space available to the cell as a result of its unique complement of chemical species and their intrinsic organization.  Learning in this context is simply a timescale separation between “fast” and “slow” processes.  Fast processes carry out computations, and the nature of these computations can be modulated by changes in slow processes.  One can also think of the behavior of an entire organism in this sense, as we (I and colleagues Greg Stephens, Antonio Costa and Tosif Ahamed) have done for the locomotory behavior of the roundworm Caenorhabditis elegans. Animal behavior also arises from biological activity across innumerable spatial and temporal scales: molecular motors contracting muscles, neurons processing an ever-changing environment, large-scale diffusion of hormones and other neuromodulatory chemicals. While it is the prevailing view that for organisms with neurons, the computational space is determined by the fast dynamics of electrical potential and learning by the slow dynamics of synaptic plasticity and connectome changes, there is no reason in principle that it cannot also be coupled to cell state and to cellular learning and computation as describe above. This may be particularly true in C. elegans, whose neuronal connections seem to be fixed during development<d-cite key="White1986-ia,Cook2019-wj"></d-cite>, and consist mainly of gap junctions rather than synapses, which results in an absence of “spiking”. The theoretical work I mention above on non-equilibrium chemical networks showed that the propensity to assemble different complexes can be modulated simply by the ratio of ATP/ADP in a cell, which is highly dependent on membrane depolarization and repolarization, especially in neurons. For C .elegans, we developed a novel analysis method that allows for complex worm behavior to be captured by Markovian dynamics with a transfer operator.  We have used this operator to coarse grain the dynamics into a hierarchy of mesoscopic states and found that the residence time in each meso-state corresponds to the probability to find food in each that state.  We hypothesize that the dynamics themselves may be modulated to encode the environment (in this case the probability of finding food) as the resulting invariant distribution.  The ability to do whole brain imaging in C. elegans<d-cite key="Brennan2019-dv, Kato2015-su, Hallinen2021-tx"></d-cite>, combined with a suite of genetic tools to modulate molecular processes on a variety of timescales, presents a unique opportunity to understand computation at the organismal level and how it connects to computations at the cellular level. I propose to look directly at how intracellular substrates may be the storage sites for the parameters of a generative model<d-cite key="Gershman2023-xu"></d-cite>, and how the continuous loop of sensory inputs, inference combining these inputs with such a model, the resulting locomotion, and molecular changes that update this model, result in the worm's dynamic model of the world.</p>
      <div class="collapse-button" onclick="toggleContent('expandableContent2')">Click to Collapse</div>
    </div>
    <div class="expandable" onclick="toggleContent('expandableContent3')">Projection operators and phenotypic manifolds</div>
      <div class="content-area" id="expandableContent3">
      <p>In the preceding, I have proposed connections between computation and learning from the molecular to the organismal level, and these extend beyond, to the level of populations and even ecosystems<d-cite key="Goyal2023-uj, De_Jesus_Astacio2021-ld"></d-cite>.  One outstanding question is how these different levels of biological organization are able to generate functional outputs that can propagate up to higher levels of organization in useful way?  How does biology manage to couple the innumerable fast degrees of freedom into meaningful collective modes<d-cite key="Furusawa2018-df"></d-cite> that span so many time and length scales? I propose that the process of learning in biological systems, at any scale, can be understood as a concentration of dimensionality.  I have studied this in the context of canalisation and plasticity in the development of populations of C. elegans in different genetic or environmental contexts. In this work I have shown that developmental variation can be captured on a low-dimensional phenotypic manifold, and that there is correspondence between within population and between population variability that may be analogous to a fluctuation response relationship.  My recent work has shown how canalisation and phenotypic plasticity in development can both arise from the projection of variations onto lower-dimensional manifolds.  Next, I would propose to develop the theoretical foundations further and subsequently resume experiments to show how genetic-developmental networks can be structured to effectively project molecular variations into phenotypic modes.  Experimentally, I plan to investigate how perturbations in well characterized pathways known to impact development, such as insulin signaling, propagate to the phenotypic manifold.  Then using a combination of standing genetic variation in recombinant inbred lines in conjunction with in-lab evolution experiments <d-cite key = "Dey2016-xa, Guzella2018-ve, Noble2017-gx"></d-cite>, I would test whether we can reshape phenotypic manifolds and look at how these new projection functions are instantiated by the underlying biological organization. In my previous work, I also found evidence for fluctuation dissipation-like relationships between traits that describe the growth and development of C. elegans. In physics, statistical mechanics provides tools to connect microscopic and macroscopic dynamics and to describe the behavior of the macroscopic observables that arise from systems with large numbers of identical interacting components. Examples include the Navier-Stokes equation for fluid flow or the Fokker-Planck equation for diffusion. For near equilibrium systems, the rigorous relationship between the fluctuations arising from the many unobserved degrees of freedom and the evolution of the system's macroscopic observables are collectively known as fluctuations-dissipation relations and can be derived analytically using projection operator theory<d-cite key="Mori1965-uy, Kubo1966-kl, Zwanzig1961-tc "></d-cite>. While biological systems are characteristically far from equilibrium, similar relations have been observed between phenotypic variability and evolutionary response<d-cite key="Sato2003-dx, Furusawa2015-hk, Tang2021-pz"></d-cite>. In fact, even in systems far from equilibrium, relations of this sort can arise when there is a separation of both observed and unobserved degrees of freedom and of time scales. I believe that concentration of dimension is a defining feature of organization in biology, allowing computations to bridge time scales and giving biological systems their unique combination of robustness and adaptability. I propose that a promising path to understanding concentration of dimension at different biological scales is a non-equilibrium extension<d-cite key="Rupe2022-op"></d-cite> to projection operator theory.</p>
      <div class="collapse-button" onclick="toggleContent('expandableContent3')">Click to Collapse</div>
    </div>

    <div class="expandable" onclick="toggleContent('expandableContent6')">References</div>
    <div class="content-area" id="expandableContent6">
      <d-appendix>
        <d-citation-list></d-citation-list>
      </d-appendix>
      <d-bibliography src="references.bib"></d-bibliography>
    
      <script type="text/javascript" src="index.bundle.js"></script>
      <div class="collapse-button" onclick="toggleContent('expandableContent6')">Click to Collapse</div>
    </div>

  </body>
  </html>